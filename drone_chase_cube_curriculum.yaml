environment_parameters:
  lesson_stage:
    curriculum:
      # --- STATIC PHASE ---
      - name: Stage0_Fixed
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 0
          threshold: 15.0 
        value: 0.0

      - name: Stage1_RandomStatic
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 0
          threshold: 15.0
        value: 1.0

      # --- CIRCLE PHASE (RAMP UP) ---
      - name: Stage2_Circle_VerySlow
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 100000 
          # CHANGED: Lowered from 18.0 to 16.0
          # Just proving it can hit a moving object is enough to speed it up.
          threshold: 16.0
        value: 2.0

      - name: Stage3_Circle_Slow
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 100000
          # CHANGED: Lowered from 19.0 to 17.0
          threshold: 17.0
        value: 3.0

      - name: Stage4_Circle_Medium
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 100000
          # CHANGED: Lowered from 20.0 to 18.0
          threshold: 18.0
        value: 4.0

      # --- RANDOM PHASE ---
      - name: Stage5_Random_Medium
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 200000
          # CHANGED: Lowered from 21.0 to 19.0
          threshold: 19.0
        value: 5.0

      - name: Stage6_Random_Fast
        value: 6.0

behaviors:
  Intercept:
    trainer_type: ppo
    hyperparameters:
      batch_size: 2048
      buffer_size: 20480
      learning_rate: 3.0e-4
      beta: 5.0e-3
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: false
      hidden_units: 512
      num_layers: 3
      vis_encode_type: simple
      memory:
        sequence_length: 64
        memory_size: 256
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000
    time_horizon: 64
    summary_freq: 50000
    # ADDED: Enable threading for Python trainer updates
    threaded: true