environment_parameters:
  # Explicitly set the radius to 40m. 
  # This ensures the agent isn't "blind" in the early stages.
  proximity_radius: 25.0

  lesson_stage:
    curriculum:
      # --- STATIC PHASE ---
      - name: Stage0_Fixed
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: false
          min_lesson_length: 0
          # CHANGED: Raised to 20.0.
          # Since a hit gives 20.0 instantly, this forces the agent to hit.
          # Farming 20.0 points takes ~8 seconds of perfect hovering, which is less efficient.
          threshold: 20
        value: 0.0

      - name: Stage1_RandomStatic
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: false
          min_lesson_length: 0
          threshold: 20
        value: 1.0

      # --- CIRCLE PHASE (RAMP UP) ---
      - name: Stage2_Circle_VerySlow
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 100000 
          # Thresholds slightly increased to ensure quality hits
          threshold: 15
        value: 2.0

      - name: Stage3_Circle_Slow
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 100000
          threshold: 15
        value: 3.0

      - name: Stage4_Circle_Medium
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 100000
          threshold: 15
        value: 4.0

      # --- RANDOM PHASE ---
      - name: Stage5_Random_Medium
        completion_criteria:
          measure: reward
          behavior: Intercept
          signal_smoothing: true
          min_lesson_length: 200000
          threshold: 15
        value: 5.0

      - name: Stage6_Random_Fast
        value: 6.0

behaviors:
  Intercept:
    trainer_type: ppo
    hyperparameters:
      batch_size: 2048
      buffer_size: 20480
      learning_rate: 3.0e-4
      beta: 5.0e-3
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: false
      hidden_units: 512
      num_layers: 3
      vis_encode_type: simple
      memory:
        sequence_length: 64
        memory_size: 256
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000
    time_horizon: 64
    summary_freq: 50000
    # Threading enabled for CPU training (remember to use --torch-device cpu)
    threaded: true